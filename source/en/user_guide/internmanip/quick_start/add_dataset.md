# ðŸ“¦ Add a New Dataset

This section explains how to register and add a custom dataset with the InternManip framework.
The process involves two main steps: **[ensuring the dataset format](#dataset-structure)** and **[registering it in code](#implementation-steps)**.



## Dataset Structure

All datasets must follow the [LeRobotDataset Format](https://github.com/huggingface/lerobot) to ensure compatibility with the data loaders and training pipelines.
The expected structure is:


```
<your_dataset_root>  # Root directory of your dataset
â”‚
â”œâ”€â”€ data  # Structured episode data in .parquet format
â”‚   â”‚
â”‚   â”œâ”€â”€ chunk-000  # Episodes 000000 - 000999
â”‚   â”‚   â”œâ”€â”€ episode_000000.parquet
â”‚   â”‚   â”œâ”€â”€ episode_000001.parquet
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ chunk-001  # Episodes 001000 - 001999
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ ...
â”‚   â”‚
â”‚   â””â”€â”€ chunk-00n  # Follows the same convention (1,000 episodes per chunk)
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ meta  # Metadata and statistical information
â”‚   â”œâ”€â”€ episodes.jsonl         # Per-episode metadata (length, subtask, etc.)
â”‚   â”œâ”€â”€ info.json              # Dataset-level information
â”‚   â”œâ”€â”€ tasks.jsonl            # Task definitions
â”‚   â”œâ”€â”€ modality.json          # Key dimensions and mapping information for each modality
â”‚   â””â”€â”€ stats.json             # Global dataset statistics (mean, std, min, max, quantiles)
â”‚
â””â”€â”€ videos  # Multi-view videos for each episode
    â”‚
    â”œâ”€â”€ chunk-000  # Videos for episodes 000000 - 000999
    â”‚   â”œâ”€â”€ observation.images.head       # Head (main front-view) camera
    â”‚   â”‚   â”œâ”€â”€ episode_000000.mp4
    â”‚   â”‚   â””â”€â”€ ...
    â”‚   â”œâ”€â”€ observation.images.hand_left  # Left hand camera
    â”‚   â””â”€â”€ observation.images.hand_right # Right hand camera
    â”‚
    â”œâ”€â”€ chunk-001  # Videos for episodes 001000 - 001999
    â”‚
    â”œâ”€â”€ ...
    â”‚
    â””â”€â”€ chunk-00n  # Follows the same naming and structure

```

> ðŸ’¡ Note: For more detailed tutorials, please refer to the [Dataset](../tutorials/dataset.md) section.

This separation of raw data, video files, and metadata makes it easier to standardize transformations and modality handling across different datasets.


<!-- > ðŸ’¡ Note: The `episodes_stats.jsonl` file under `meta/` is optional and can be omitted. -->

## Implementation Steps

### Register a Dataset Class

Create a new dataset class under `internmanip/datasets/`, inheriting from `LeRobotDataset`:

```python
from internmanip.datasets import LeRobotDataset

class CustomDataset(LeRobotDataset):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

    def load_data(self):
        # Implement custom data loading logic here
        pass
```

This class defines how to read your datasetâ€™s raw files and convert them into a standardized format for training.

### Define a Data Configuration

Each dataset needs a data configuration class that specifies modalities, keys, and transformations.
Create a new configuration file under `internmanip/configs/data_configs/`. Hereâ€™s a minimal example:

```python
class CustomDataConfig(BaseDataConfig):
    """Data configuration for the custom dataset."""
    video_keys = ["video.rgb"]
    state_keys = ["state.pos"]
    action_keys = ["action.delta_pos"]
    language_keys = ["annotation.instruction"]

    # Temporal indices
    observation_indices = [0]         # Current timestep for observations
    action_indices = list(range(16))  # Future timesteps for actions (0-15)

    def modality_config(self) -> dict[str, ModalityConfig]:
        """Define modality configurations."""
        return {
            "video": ModalityConfig(self.observation_indices, self.video_keys),
            "state": ModalityConfig(self.observation_indices, self.state_keys),
            "action": ModalityConfig(self.action_indices, self.action_keys),
            "language": ModalityConfig(self.observation_indices, self.language_keys),
        }

    def transform(self):
        """Define preprocessing pipelines."""
        return [
            # Video preprocessing
            VideoToTensor(apply_to=self.video_keys),
            VideoResize(apply_to=self.video_keys, height=224, width=224),

            # State preprocessing
            StateActionToTensor(apply_to=self.state_keys),
            StateActionTransform(
                apply_to=self.state_keys,
                normalization_modes={"state.pos": "mean_std"},
            ),

            # Action preprocessing
            StateActionToTensor(apply_to=self.action_keys),
            StateActionTransform(
                apply_to=self.action_keys,
                normalization_modes={"action.delta_pos": "mean_std"},
            ),

            # Concatenate modalities
            ConcatTransform(
                video_concat_order=self.video_keys,
                state_concat_order=self.state_keys,
                action_concat_order=self.action_keys,
            ),
        ]
```

### Register Your Config

Finally, register your custom config by adding it to `DATA_CONFIG_MAP`.


```python
DATA_CONFIG_MAP = {
    ...,
    "custom": CustomDataConfig(),
}
```

> ðŸ’¡ Tips: Adjust the key names (`video_keys`, `state_keys`, etc.) and `normalization_modes` based on your dataset. For multi-view video or multi-joint actions, just add more keys and update the transforms accordingly.

This config sets up how to load and process different modalities, and ensures compatibility with the training framework.

### What's Next?
After registration, you can use your dataset by passing `--dataset_path <path>` and `--data_config custom` to the training YAML file.
